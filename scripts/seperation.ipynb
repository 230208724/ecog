{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from utils import *\n",
    "\n",
    "# shareDir = os.path.abspath('../..')\n",
    "# sys.path.append(shareDir)\n",
    "# from bciBASE.server import EEG_data\n",
    "\n",
    "scriptsDir = os.path.abspath('.')\n",
    "presentationsDir = os.path.abspath(rf'{scriptsDir}/../presentation')\n",
    "mannualDataDir = os.path.abspath(rf'{scriptsDir}/../manualData')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# true labelled fist_rest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h:\\BCIteam_Allrelated\\SharedSource\\ecog\\manualData/fist/JMF\\60s70s68s.mat\n",
      "  date   \n",
      "7   -1  \\\n",
      "\n",
      "  info((hypothesis that all operations are for left tumor and all actions are on right))   \n",
      "7                                  唤醒下左额顶开颅术：连续握拳1分钟                                      \\\n",
      "\n",
      "  predictedtime paradigm subject subjectid  age  sexual               tumor   \n",
      "7           60s     fist     JMF    sub006   53  female  left top forehead'  \\\n",
      "\n",
      "   epilepsy      data time  freq   \n",
      "7         1  32x35000  70s   500  \\\n",
      "\n",
      "                                             channel  \n",
      "7  ['s6c1','s6c2','s6e1','s6e2','s6e3','s6e4','s6...  \n",
      "(2, 34248)\n"
     ]
    }
   ],
   "source": [
    "paradigm = 'fist'\n",
    "subject = 'JMF'\n",
    "fistDataMATFile = glob.glob(rf'{mannualDataDir}/{paradigm}/{subject}/*.mat')[0]\n",
    "fistDataFDTFile = fistDataMATFile.replace('.mat','.fdt')\n",
    "if not os.path.exists(fistDataFDTFile): raise\n",
    "fistDataSETFile = fistDataFDTFile.replace('.mat','.set')\n",
    "if not os.path.exists(fistDataSETFile): raise\n",
    "\n",
    "infoFile = rf'{presentationsDir}/info.xlsx'\n",
    "infoDf = pd.read_excel(infoFile)\n",
    "info = infoDf[(infoDf['subject']==subject)&(infoDf['paradigm']==paradigm)]\n",
    "channel = eval(info['channel'].values[0])\n",
    "\n",
    "invalidChannelNum = 7\n",
    "validChannel = channel[:-invalidChannelNum]\n",
    "validChannelNum = len(validChannel)\n",
    "\n",
    "fistData = read_file(fistDataMATFile)[:validChannelNum,:]\n",
    "\n",
    "print(fistDataMATFile)\n",
    "print(info)\n",
    "print(fistData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h:\\BCIteam_Allrelated\\SharedSource\\ecog\\manualData/rest/JMF\\180s234s224s.mat\n",
      "  date   \n",
      "6   -1  \\\n",
      "\n",
      "  info((hypothesis that all operations are for left tumor and all actions are on right))   \n",
      "6                                    唤醒下左额顶开颅术：静息3分钟                                      \\\n",
      "\n",
      "  predictedtime paradigm subject subjectid  age  sexual               tumor   \n",
      "6          180s     rest     JMF    sub006   53  female  left top forehead'  \\\n",
      "\n",
      "   epilepsy       data  time  freq   \n",
      "6         1  32x117000  234s   500  \\\n",
      "\n",
      "                                             channel  \n",
      "6  ['s6c1','s6c2','s6e1','s6e2','s6e3','s6e4','s6...  \n",
      "(2, 111924)\n"
     ]
    }
   ],
   "source": [
    "paradigm = 'rest'\n",
    "subject = 'JMF'\n",
    "restDataMATFile = glob.glob(rf'{mannualDataDir}/{paradigm}/{subject}/*.mat')[0]\n",
    "restDataFDTFile = restDataMATFile.replace('.mat','.fdt')\n",
    "if not os.path.exists(restDataFDTFile): raise\n",
    "restDataSETFile = restDataFDTFile.replace('.mat','.set')\n",
    "if not os.path.exists(restDataSETFile): raise\n",
    "\n",
    "infoFile = rf'{presentationsDir}/info.xlsx'\n",
    "infoDf = pd.read_excel(infoFile)\n",
    "info = infoDf[(infoDf['subject']==subject)&(infoDf['paradigm']==paradigm)]\n",
    "channel = eval(info['channel'].values[0])\n",
    "\n",
    "invalidChannelNum = 7\n",
    "validChannel = channel[:-invalidChannelNum]\n",
    "validChannelNum = len(validChannel)\n",
    "\n",
    "restData = read_file(restDataMATFile)[:validChannelNum,:]\n",
    "\n",
    "print(restDataMATFile)\n",
    "print(info)\n",
    "print(restData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model to classify timestep epoch is rest or fist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, p, classes, ifprint=False):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.p = p\n",
    "        self.classes = classes\n",
    "        self.ifprint = ifprint\n",
    "               \n",
    "        self.conv1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,out_channels=4, kernel_size=(1,7),stride=(1,1),padding=(0,3)),\n",
    "            nn.Dropout(0.2), \n",
    "            nn.BatchNorm2d(num_features=4),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "            )  \n",
    "        self.conv2=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4,out_channels=8,kernel_size=(3,3),stride=(1,1),padding=(1,1)),\n",
    "            nn.Dropout(0.2), \n",
    "            nn.BatchNorm2d(num_features=8),\n",
    "            nn.ELU(),       \n",
    "            nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "            )\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.p,self.classes,bias=True),\n",
    "            )\n",
    "\n",
    "    def forward(self,x):\n",
    "        if self.ifprint: print(x.size())\n",
    "        output1=self.conv1(x)\n",
    "        if self.ifprint: print(output1.size())\n",
    "        output2=self.conv2(output1)  \n",
    "        if self.ifprint: print(output2.size())\n",
    "        output3=output2.reshape(output2.size(0),-1)\n",
    "        if self.ifprint: print(output3.size())\n",
    "        output=self.out(output3)\n",
    "        if self.ifprint: print(output.size())\n",
    "        return output\n",
    "\n",
    "def torch_data(data):\n",
    "    if type(data)==np.ndarray:\n",
    "        return torch.from_numpy(data).float()\n",
    "    if type(data)==pd.core.frame.DataFrame:\n",
    "        return torch.from_numpy(data.values).float()\n",
    "        \n",
    "class classifyDataset(Dataset):\n",
    "    def __init__(self, data0, data1, timeStep,\n",
    "                 normalize=False, normalizeBy='', normalizeMethod='',\n",
    "                 flatten=False):\n",
    "        self.data0 = data0\n",
    "        self.data1 = data1\n",
    "        self.timeStep = timeStep\n",
    "        self.lenData0 = data0.shape[1]\n",
    "        self.numSample0 = self.lenData0 - self.timeStep + 1\n",
    "        self.lenData1 = data1.shape[1]\n",
    "        self.numSample1 = self.lenData1 - self.timeStep + 1\n",
    "        self.numSample = self.numSample0 + self.numSample1\n",
    "        \n",
    "        self.normalize = normalize\n",
    "        self.normalizeBy = normalizeBy\n",
    "        self.normalizeMethod = normalizeMethod\n",
    "\n",
    "        self.flatten = flatten\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.numSample\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.numSample1:\n",
    "            data = self.data0[:, idx : idx + self.timeStep]\n",
    "            label = 0\n",
    "        else:\n",
    "            data = self.data1[:, (idx - self.numSample1) : (idx - self.numSample1) + self.timeStep]\n",
    "            label = 1\n",
    "        if self.normalize: data = normalize(data,by=self.normalizeBy,method=self.normalizeMethod) \n",
    "        if self.flatten: data = flatten_data(data)\n",
    "        return torch_data(data), torch.tensor(label)\n",
    "\n",
    "data0 = fistData\n",
    "data1 = restData\n",
    "timeStep = 500\n",
    "classifydataset = classifyDataset(data0, data1, timeStep)\n",
    "train_size = int(classifydataset.__len__() * 0.8)\n",
    "test_size = classifydataset.__len__() - train_size \n",
    "train_dataset, test_dataset = random_split(classifyDataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=int(train_dataset.__len__()/10), shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_dataset.__len__(), shuffle=False)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    device = torch.device('cuda')\n",
    "    print('device is gpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('device is cpu')\n",
    "\n",
    "cnn = CNN(p=8*int(int(validChannelNum/2)/2)*int(int(timeStep/2)/2),\n",
    "        classes=2,\n",
    "        ifprint=False).to(device)\n",
    "optimizer=torch.optim.Adam(cnn.parameters(), lr=0.003, weight_decay=1e-5)\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "\n",
    "ModelDf = pd.DataFrame(columns = ['epoch','step','loss','trainAcc','testAcc'])\n",
    "irow = 0\n",
    "test_accuracy_best = 0\n",
    "epoch = 0\n",
    "while (epoch<5) or (test_accuracy_best<0.5 and epoch<20):\n",
    "    for step, (batch_data,batch_label) in enumerate(train_loader):\n",
    "        batch_data = torch.unsqueeze(batch_data,1).to(device)\n",
    "        batch_label = batch_label.to(device)\n",
    "        output = cnn(batch_data)\n",
    "        loss = loss_fn(output, batch_label)\n",
    "        optimizer.zero_grad()   \n",
    "        loss.backward()         \n",
    "        optimizer.step() \n",
    "        x_pred = torch.max(output,1)[1].data.squeeze()\n",
    "        train_accuracy = sum(x_pred==batch_label).item()/batch_label.size(0)\n",
    "        for _,(test_data,test_label) in enumerate(test_loader):\n",
    "            test_data = torch.unsqueeze(test_data,1).to(device)\n",
    "            test_label = test_label.to(device)\n",
    "            test_output = cnn(test_data)\n",
    "            y_pred = torch.max(test_output,1)[1].data.squeeze()\n",
    "            test_accuracy=sum(y_pred==test_label).item()/test_label.size(0)\n",
    "            test_accuracy_best = test_accuracy_best if test_accuracy_best>test_accuracy else test_accuracy \n",
    "            ModelDf.loc[irow] = [epoch+1,step+1,round(loss.item(),4),round(train_accuracy,4),round(test_accuracy,4)]\n",
    "            print(f'epoch: {epoch+1} | step: {step+1} | loss: {round(loss.item(),4)} | train_acc: {round(train_accuracy,4)} | test_acc: {round(test_accuracy,4)}')     \n",
    "            irow += 1\n",
    "    epoch += 1\n",
    "\n",
    "ModelDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for decision on reseaonal seperation timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegementationDataset(Dataset):\n",
    "    def __init__(self, data0, data1, step,\n",
    "                 normalize=False, normalizeBy='', normalizeMethod='',\n",
    "                 flatten=False):\n",
    "        self.step = step\n",
    "        self.lenData0 = data0.shape[1]\n",
    "        self.numSample0 = self.lenData0 - self.step + 1\n",
    "        self.lenData1 = data1.shape[1]\n",
    "        self.numSample1 = self.lenData1 - self.step + 1\n",
    "        self.numSample = self.numSample0 * self.numSample1\n",
    "        \n",
    "        self.normalize = normalize\n",
    "        self.normalizeBy = normalizeBy\n",
    "        self.normalizeMethod = normalizeMethod\n",
    "\n",
    "        self.flatten = flatten\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.numSample\n",
    "    def __getitem__(self, idx):\n",
    "        idx0 = int( idx / self.numSample1 )\n",
    "        idx1 = idx % self.numSample1\n",
    "        idata0 = self.data0[:, idx0:idx0 + self.step]\n",
    "        idata1 = self.data1[:, idx1:idx0 + self.step]\n",
    "        if self.normalize: data = normalize(data,by=self.normalizeBy,method=self.normalizeMethod) \n",
    "        if self.flatten: data = flatten_data(data)\n",
    "        label = self.labels[idx]\n",
    "        return torch_data(data), torch.tensor(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
